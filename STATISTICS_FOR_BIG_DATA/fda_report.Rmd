---
title: "Mathematics for Big Data -  Exercise 2b"
author: Lawrence Adu-Gyamfi (1484610)
date: 10/06/2019
output:
  pdf_document: 
    fig_caption: yes
    number_sections: yes
    toc: yes
classoption: 11pt
header-includes: 
  \usepackage{float}
  \floatplacement{figure}{H}
  #html_notebook: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.pos='h', echo = FALSE)
```

\newpage
# INTRODUCTION

This report presents the code and the results of functional data analysis of the medfly data.

The medfly data have been a popular dataset for functional data analysis.The data consist of records of the number of eggs laid by 50 fruit flies on each of 31 days, along with each individual???s total lifespan.

# Question 1

The following section uses code provided in the assignment for smoothing the data for the number of eggs and choosing the smoothing parameter by GCV (Generalized Cross-Validation).

```{r echo=F, message=FALSE, warning=F, results="hide"}
require(fda)
require(data.table)
require(knitr)
load('medfly.Rdata') #if working directory is set to source file???s.Otherwise put  path.
lifetime = as.numeric(medfly$lifetime)
medbasis = create.bspline.basis(c(0,25),norder=4,breaks=0:25)
lambdas = exp(-10:10)
gcvs = rep(0,length(lambdas))
for(i in 1:length(lambdas)){
  mPar = fdPar(medbasis,int2Lfd(2),lambdas[i])
  gcvs[i] = mean(smooth.basis(0:25,medfly$eggcount,mPar)$gcv)
}
best = which.min(gcvs)
lambda = lambdas[best]
mPar = fdPar(medbasis,int2Lfd(2),lambda)
medfd = smooth.basis(0:25,medfly$eggcount,mPar)
```

```{r echo=F}
cat("The best lambda used for smoothing is: ", lambda)

```
## Question

Plot the smoothed data.

## Solution
Below is a plot of the smoothed data showing the number of eggs laid by each of the different fruit flies as a function of time (day).

```{r echo=F, fig.cap="Plot of smoothed medfly dataset.", fig.heigt=2, fig.asp=0.6, results="hide"}

plot(medfd, main="Plot of Medfly Data for 50 Fruit Flies", xlab="Day",ylab="Number of eggs laid")

```

\newpage
# Question 2
## Question

Conduct a principal components analysis using these smooths. Are the components inter- pretable? How many do you need to retain to recover 90% of the variation.

## Solution
Below are the results of the explained variability for each of the principal components. The cummulated sum is shown as well to show many principal components help to recover most of the variability.
```{r echo=F, results="asis"}
# calculate the Principal components
med.pca = pca.fd(medfd$fd,nharm=10)
med.var = med.pca$varprop

# view variability explained by each of the PCs
kable(data.table(PC=seq(length(med.var)), Variability_Explained=round(med.var, digits=3), CUMSUM=round(cumsum(med.var), digits=3) ), caption="PCA results")
```

```{r echo=FALSE, fig.cap="Plot of Variability Explained by Principal Components of Medfly Dataset", fig.height=4}
# Plot the variability explained with the PCs
plot(med.var,type='b', xlab="Principal Components", ylab="Variability Explained", main="Plot of Variability Explained by Principal Components")
text(med.var, labels=round(cumsum(med.var), digits=2), pos=4, col="red")

```

We are able to recover more than 90% of the variability using between 2 and 3 principal components, and by the 5th principal component, almost all the variability is recovered.

The following plots show the first 3 principal components.

```{r echo=F, fig.cap="First 3 Principal Components", fig.height=4, results="hide"}
# view the Principal components
plot(med.pca$harmonics[1:3], xlab="Day", lty=c(seq(3)), col=c("red","green","blue"), main="First 3 Principal Components")
legend('bottomright', legend=med.pca$harmonics$fdnames[[2]][1:3], lty=c(seq(3)), col=c("red","green","blue"))
```

```{r echo=F, fig.cap="Individual Plots of first 3 Principal Components", fig.height=7}
# plot the inidividual PCs
par(mfrow=c(3,1))
plot(med.pca,harm=1:3,ylab="Day")
```


Comparing the plots of the principal components to the plot of the entire dataset, the first principal component seems to describe the total eggs laid over the entire period for each day, which makes sense for this recover much of the variability of the dataset.



\newpage
# Question 3

## Question

Perform a functional linear regression to predict the total lifespan of the fly from their egg laying. Choose a smoothing parameter by cross validation, and plot the coefficient function along with confidence intervals.

## Solution

```{r echo=F, results="hide"}
xfdlist = list(rep(1,50),medfd$fd)
xfdlist

# create basic functional parameter object
cPar = fdPar(fdobj=create.constant.basis(),
             Lfdobj=0,
             lambda=0)

# Perform leave one out cross validation to get best smoothing parameter
cross.vals = rep(0, length(lambdas))
for (i in 1:length(lambdas)){
  aux.par=fdPar(fdobj=medbasis, int2Lfd(m=2), lambdas[i])
  cross.vals[i] = fRegress(lifetime,xfdlist,list(cPar,aux.par))$OCV
}

best_lambda = lambdas[which.min(cross.vals)]

# return final functional parameter object for the regression
aux.par = fdPar(fdobj=medbasis, Lfdobj=int2Lfd(m=2),
                best_lambda)

med.reg = fRegress(y=lifetime, xfdlist=xfdlist, betalist=list(cPar, aux.par))

```

```{r}
cat("Best lambda used for the regression is: ", best_lambda)
```

The following plot shows the predicted values of total lifespan returned by the model against the actual values of the dataset.

```{r echo=F,results="hide", fig.cap="Plot of fitted values against actual lifespan"}
# view predictions against actual values
plot(med.reg$yhatfdobj,lifetime,xlab='Lifespan (predictions) ',ylab= 'Lifespan (actuals)', main="Predictions vs. Actuals of Lifespan", pty="s", pch=5)
abline(c(0,1), col="red", lwd=2)
```

Presented below is the coefficient function of the model along with 95% confidence interval.

```{r echo=F, fig.cap="Coefficient Function of Functional Linear Regression Model"}
# view coefficient function
med.var = sum( (lifetime-med.reg$yhatfdobj)^2 )/(50-med.reg$df)

med.std = fRegress.stderr(med.reg,NULL,med.var*diag(rep(1,50)))

med.coeffun = med.reg$betaestlist[[2]]

plot(med.coeffun$fd,ylim=c(-5,5), ylab="Coefficient Values",xlab="Day" )
lines(med.reg$betaestlist[[2]]$fd+2*sqrt(med.std$betastderrlist[[2]]),lty=2, col="red", main="Coeffient Function (Functional Linear Regression")
lines(med.reg$betaestlist[[2]]$fd-2*sqrt(med.std$betastderrlist[[2]]),lty=2, col="red")

```


\newpage
# Question 4

## Question

Conduct a permutation test for the significance of the regression. Calculate the R2 for your regression.

## Solution

Below are the results of the permutation testing of the model to verify its significance over a confidence interval of 95%.

```{r echo=F, fig.cap="Permutation Testing Results"}
# Verify significance of model by permutation testing
med.permtest = Fperm.fd(yfdPar=lifetime, xfdlist=xfdlist,
                        betalist=list(cPar, aux.par), q=0.95)

cat("The p-value is :", med.permtest$pval)

```

From the results of the P-value we can verify that indeed the functional regression model is significant.

Below is the R_squared (coefficient of determination) of the model.

```{r echo=F}

# Calculate R_squared of Model
med.rsq = 1 - med.var / var(lifetime)

cat("R_squared of regression model is: ", med.rsq)
```



\newpage
# Question 5

## Question
Try a linear regression of lifespan on the principal component scores from your analysis. What is the R2 for this model? Does lm find that the model is significant? Reconstruct and plot the coefficient function for this model along with confidence intervals. How does it compare to the model obtained through functional linear regression?

## Solution

In this section a linear regression model is set up using the scores of the principal components calculated earlier. Even though, it was estimated that the first 3 principal components of the dataset captured over 90% of the variability, the model created here uses all the principal components (10).

```{r echo=F, results="hide"}
# get scores for all the principal components calculated previously
pca.scores <- med.pca$scores

#create linear model
med.pca.mod <- lm(lifetime ~ pca.scores)
```

```{r echo=F}
summary(med.pca.mod)
```

Below the results of the linear regression models of both the PCA scores and the functional linear regression are compared.

```{r echo=F, fig.cap="Comparison of PCA and Functional Regression Models Based on Fitted Values", fig.height=8, results="hide"}
#compare results with functional linear regression model
par(mfrow=c(2,1))
plot(med.pca.mod$fitted, lifetime, xlab="Lifespan (predictions)", ylab="Lifespan (Actuals)", main="PCA Linear Regression Model")
abline(c(0,1), col="red", lwd=2)

plot(med.reg$yhatfdobj,lifetime,xlab='predictions',ylab='actuals', main="Functional Linear Regression Model", pty="s", pch=5)
abline(c(0,1), col="red", lwd=2)

```

From the above, it is evident that a similar trend and predictive performance is achieved by both models.


Below the coefficient function of the linear regression model of the principal components is reconstructed and compared with that of the functional linear regression model.

The confidence interval of both models are presented in red as well in the plots.

```{r echo=F, fig.cap="Comparison of PCA and Functional Regression Models Based on Coefficient Functions", fig.height=6, results="hide"}
# reconstruct coefficient function

med.coef = med.pca.mod$coefficients
med.coefvar = summary(med.pca.mod)$coefficients[,2]

med.pcabeta = med.coef[2]*med.pca$harmonics[1]
med.pcavar = med.coefvar[2]^2 * med.pca$harmonics[1]^2

# iterate through coefficients and add up all harmonics
for (i in 2:dim(pca.scores)[2]){
  med.pcabeta = med.pcabeta + med.coef[i+1]*med.pca$harmonics[i]
  med.pcavar = med.pcavar + med.coefvar[i+1]^2 * med.pca$harmonics[i]^2
}

# compare plot of pca reconstructed coeffficient function with that of functional regression 
par(mfrow=c(2,1))
plot(med.pcabeta, main="PCA Regression coefficient Function", ylim=c(-20,20), ylab="Coefficient Values",
     xlab="Day")
lines(med.pcabeta + 2*sqrt(med.pcavar), lty=2, col="red")
lines(med.pcabeta - 2*sqrt(med.pcavar), lty=2, col="red")

plot(med.coeffun$fd,ylim=c(-5,5), main="Functional Linear Regression CoefficientFunction",
     ylab="Coefficient Values", xlab="Day")
lines(med.reg$betaestlist[[2]]$fd+2*sqrt(med.std$betastderrlist[[2]]),lty=2, col="red")
lines(med.reg$betaestlist[[2]]$fd-2*sqrt(med.std$betastderrlist[[2]]),lty=2, col="red")

```

A similar trend of the coefficient function is observed in both models built from the principal components and using functional linear regression respectively.

# References

1. Lecture Notes - Introduction to functional data analysis - Alejandra Cabana Nigro

2. http://faculty.bscb.cornell.edu/~hooker/FDA2008/




